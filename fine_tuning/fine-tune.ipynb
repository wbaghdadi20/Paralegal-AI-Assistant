{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "# systemPrompt = input(\"\\nSystem Prompt: \")\n",
    "# if systemPrompt == \"\":\n",
    "#     systemPrompt = \"Answer only yes or no.\"\n",
    "#     print(\"System Prompt: \" + systemPrompt)\n",
    "\n",
    "# while True:\n",
    "#     userPrompt = input(\"User Prompt: \")\n",
    "#     stream = client.chat.completions.create(\n",
    "#         model=\"gpt-4-preview\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": systemPrompt},\n",
    "#             {\"role\": \"user\", \"content\": userPrompt}\n",
    "#         ],\n",
    "#         stream=True,\n",
    "#     )\n",
    "#     print(\"GPT Response:\\n\")\n",
    "#     for chunk in stream:\n",
    "#         print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 20\n",
      "First example:\n",
      "{'role': 'system', 'content': \"You are an AI assistant trained extensively in U.S. immigration law, acting as a paralegal or lawyer. Your role is to provide expert assistance on immigration matters, including but not limited to visas, green cards, citizenship, asylum, and deportation processes. You must offer accurate, up-to-date legal advice, help users understand complex legal concepts, and guide them through the immigration process.\\n\\nWhen interacting with users:\\n\\n1. Provide detailed, clear, and precise legal information relevant to their inquiries.\\n2. Analyze and interpret the user's situation based on the information they provide, offering guidance that aligns with current U.S. immigration laws and policies.\\n3. Assist in preparing and reviewing immigration-related documents, ensuring they meet legal standards.\\n4. Maintain a professional, empathetic, and supportive tone throughout the interaction.\\n5. Keep user information confidential and secure, adhering to legal and ethical standards.\\n6. Clarify that while you provide legal information, users should consult with a licensed attorney for personalized legal advice.\\n\\nYour responses should reflect your advanced training in immigration law, focusing on delivering value and clarity to users seeking assistance with immigration-related issues.\"}\n",
      "{'role': 'user', 'content': 'What type of visa do I need to study in the U.S.?'}\n",
      "{'role': 'assistant', 'content': 'To study in the U.S., you typically need an F-1 student visa. This visa is designed for individuals who plan to pursue academic studies at an accredited institution or English language studies. There are also M-1 visas for vocational or non-academic studies and J-1 visas for exchange visitors, which can include some students.'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"test.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Document to Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-cGQgL5ery0uvojER2y5TzJKJ', bytes=35307, created_at=1709504557, filename='test.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-HMoJSpXc4uJnTMKpziZ9UjUf', created_at=1709505943, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-FJKCJbjBRzPKYKf1E9TZqScl', result_files=[], status='validating_files', trained_tokens=None, training_file='file-cGQgL5ery0uvojER2y5TzJKJ', validation_file=None, user_provided_suffix=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-cGQgL5ery0uvojER2y5TzJKJ\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatting With Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "systemPrompt = \"You are an AI assistant trained extensively in U.S. immigration law, acting as a paralegal or lawyer. Your role is to provide expert assistance on immigration matters, including but not limited to visas, green cards, citizenship, asylum, and deportation processes. You must offer accurate, up-to-date legal advice, help users understand complex legal concepts, and guide them through the immigration process.\\n\\nWhen interacting with users:\\n\\n1. Provide detailed, clear, and precise legal information relevant to their inquiries.\\n2. Analyze and interpret the user's situation based on the information they provide, offering guidance that aligns with current U.S. immigration laws and policies.\\n3. Assist in preparing and reviewing immigration-related documents, ensuring they meet legal standards.\\n4. Maintain a professional, empathetic, and supportive tone throughout the interaction.\\n5. Keep user information confidential and secure, adhering to legal and ethical standards.\\n6. Clarify that while you provide legal information, users should consult with a licensed attorney for personalized legal advice.\\n\\nYour responses should reflect your advanced training in immigration law, focusing on delivering value and clarity to users seeking assistance with immigration-related issues.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Response:\n",
      "\n",
      "While a misdemeanor arrest won't lead to immediate visa revocation, certain crimes could impact your visa status and future immigration opportunities. Inform your DSO about the arrest, follow legal proceedings, and seek advice from an immigration attorney."
     ]
    }
   ],
   "source": [
    "userPrompt = input(\"User Prompt: \")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0125:personal::8yogN9zm\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": systemPrompt},\n",
    "        {\"role\": \"user\", \"content\": userPrompt}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "print(\"GPT Response:\\n\")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate QnA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get .env file regardless of which directory you're in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def find_project_root(current_directory, marker):\n",
    "    current_directory = Path(current_directory).absolute()\n",
    "    for parent in current_directory.parents:\n",
    "        if (parent / marker).exists():\n",
    "            return parent\n",
    "    raise FileNotFoundError(f\"Project root with {marker} not found\")\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "project_root = find_project_root(current_directory, '.git')\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "env_path = project_root / '.env'\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI() # uses Jinyue's GPT-4 model\n",
    "# print(client.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_line_string_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Read the file content and replace newlines with spaces\n",
    "        single_line_content = file.read().replace('\\n', ' ')\n",
    "    return single_line_content\n",
    "    \n",
    "system_prompt_expert = load_single_line_string_from_file('immigration_expert_model_prompt.txt')\n",
    "system_prompt_query = load_single_line_string_from_file('immigration_query_model_prompt.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
