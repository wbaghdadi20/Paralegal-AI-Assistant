{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 20\n",
      "First example:\n",
      "{'role': 'system', 'content': \"You are an AI assistant trained extensively in U.S. immigration law, acting as a paralegal or lawyer. Your role is to provide expert assistance on immigration matters, including but not limited to visas, green cards, citizenship, asylum, and deportation processes. You must offer accurate, up-to-date legal advice, help users understand complex legal concepts, and guide them through the immigration process.\\n\\nWhen interacting with users:\\n\\n1. Provide detailed, clear, and precise legal information relevant to their inquiries.\\n2. Analyze and interpret the user's situation based on the information they provide, offering guidance that aligns with current U.S. immigration laws and policies.\\n3. Assist in preparing and reviewing immigration-related documents, ensuring they meet legal standards.\\n4. Maintain a professional, empathetic, and supportive tone throughout the interaction.\\n5. Keep user information confidential and secure, adhering to legal and ethical standards.\\n6. Clarify that while you provide legal information, users should consult with a licensed attorney for personalized legal advice.\\n\\nYour responses should reflect your advanced training in immigration law, focusing on delivering value and clarity to users seeking assistance with immigration-related issues.\"}\n",
      "{'role': 'user', 'content': 'What type of visa do I need to study in the U.S.?'}\n",
      "{'role': 'assistant', 'content': 'To study in the U.S., you typically need an F-1 student visa. This visa is designed for individuals who plan to pursue academic studies at an accredited institution or English language studies. There are also M-1 visas for vocational or non-academic studies and J-1 visas for exchange visitors, which can include some students.'}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"test.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Document to Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-cGQgL5ery0uvojER2y5TzJKJ', bytes=35307, created_at=1709504557, filename='test.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client.files.create(\n",
    "  file=open(\"test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-HMoJSpXc4uJnTMKpziZ9UjUf', created_at=1709505943, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-FJKCJbjBRzPKYKf1E9TZqScl', result_files=[], status='validating_files', trained_tokens=None, training_file='file-cGQgL5ery0uvojER2y5TzJKJ', validation_file=None, user_provided_suffix=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-cGQgL5ery0uvojER2y5TzJKJ\", \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatting With Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "systemPrompt = \"You are an AI assistant trained extensively in U.S. immigration law, acting as a paralegal or lawyer. Your role is to provide expert assistance on immigration matters, including but not limited to visas, green cards, citizenship, asylum, and deportation processes. You must offer accurate, up-to-date legal advice, help users understand complex legal concepts, and guide them through the immigration process.\\n\\nWhen interacting with users:\\n\\n1. Provide detailed, clear, and precise legal information relevant to their inquiries.\\n2. Analyze and interpret the user's situation based on the information they provide, offering guidance that aligns with current U.S. immigration laws and policies.\\n3. Assist in preparing and reviewing immigration-related documents, ensuring they meet legal standards.\\n4. Maintain a professional, empathetic, and supportive tone throughout the interaction.\\n5. Keep user information confidential and secure, adhering to legal and ethical standards.\\n6. Clarify that while you provide legal information, users should consult with a licensed attorney for personalized legal advice.\\n\\nYour responses should reflect your advanced training in immigration law, focusing on delivering value and clarity to users seeking assistance with immigration-related issues.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Response:\n",
      "\n",
      "While a misdemeanor arrest won't lead to immediate visa revocation, certain crimes could impact your visa status and future immigration opportunities. Inform your DSO about the arrest, follow legal proceedings, and seek advice from an immigration attorney."
     ]
    }
   ],
   "source": [
    "userPrompt = input(\"User Prompt: \")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"ft:gpt-3.5-turbo-0125:personal::8yogN9zm\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": systemPrompt},\n",
    "        {\"role\": \"user\", \"content\": userPrompt}\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "print(\"GPT Response:\\n\")\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automate QnA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get .env file regardless of which directory you're in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-nyQmuRs6rAhBh2jpxRCTT3BlbkFJCJx2zZ7yAvDKF13IcySw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "def find_project_root(current_directory, marker):\n",
    "    current_directory = Path(current_directory).absolute()\n",
    "    for parent in current_directory.parents:\n",
    "        if (parent / marker).exists():\n",
    "            return parent\n",
    "    raise FileNotFoundError(f\"Project root with {marker} not found\")\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "project_root = find_project_root(current_directory, '.git')\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "env_path = project_root / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "client = OpenAI() # uses Jinyue's GPT-4 model\n",
    "print(client.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_line_string_from_file(file_path, delim=' '):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read().replace('\\n', delim)\n",
    "    \n",
    "system_prompt_expert = load_single_line_string_from_file('immigration_expert_model_prompt.txt')\n",
    "system_prompt_query = load_single_line_string_from_file('immigration_query_model_prompt.txt')\n",
    "system_prompt = load_single_line_string_from_file('system_prompt.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_content_as_json(question, answer, filename):\n",
    "    directory = \"JSONL\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    data = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question},\n",
    "            {\"role\": \"assistant\", \"content\": answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    \n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=0)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qna(file_content):\n",
    "    questions = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt_query},\n",
    "            {\"role\": \"user\", \"content\": file_content}\n",
    "        ],\n",
    "        model=\"gpt-4-turbo\"\n",
    "    )\n",
    "    questions = questions.choices[0].message.content.replace('\\n', ' ').split('###')[1:]\n",
    "\n",
    "    answers = []\n",
    "    for question in questions:\n",
    "        answer = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt_expert},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            model=\"gpt-4-turbo\"\n",
    "        )\n",
    "        answers.append(answer.choices[0].message.content.replace('\\n', ' '))\n",
    "\n",
    "    # for question, answer in zip(questions, answers):\n",
    "    #     print(f\"Question: {question}\")\n",
    "    #     print(f\"Answer: {answer}\\n\")\n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_directory(directory):\n",
    "    i = 1\n",
    "    for dirpath, _, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            if i <= 110:\n",
    "                i += 1\n",
    "                continue\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            file_content = load_single_line_string_from_file(full_path)\n",
    "            questions, answers = qna(file_content)\n",
    "            for question, answer in zip(questions, answers):\n",
    "                format_content_as_json(question, answer, re.sub(r'\\.txt$', '.jsonl', filename))\n",
    "            \n",
    "explore_directory('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def format_error_check(data, filename):\n",
    "    # Format error checks\n",
    "    format_errors = defaultdict(int)\n",
    "\n",
    "    for ex in data:\n",
    "        if not isinstance(ex, dict):\n",
    "            format_errors[\"data_type\"] += 1\n",
    "            continue\n",
    "            \n",
    "        messages = ex.get(\"messages\", None)\n",
    "        if not messages:\n",
    "            format_errors[\"missing_messages_list\"] += 1\n",
    "            continue\n",
    "            \n",
    "        for message in messages:\n",
    "            if \"role\" not in message or \"content\" not in message:\n",
    "                format_errors[\"message_missing_key\"] += 1\n",
    "            \n",
    "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
    "                format_errors[\"message_unrecognized_key\"] += 1\n",
    "            \n",
    "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "                format_errors[\"unrecognized_role\"] += 1\n",
    "                \n",
    "            content = message.get(\"content\", None)\n",
    "            function_call = message.get(\"function_call\", None)\n",
    "            \n",
    "            if (not content and not function_call) or not isinstance(content, str):\n",
    "                format_errors[\"missing_content\"] += 1\n",
    "        \n",
    "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "            format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "    if format_errors:\n",
    "        print(f\"Found errors in {filename}:\")\n",
    "        for k, v in format_errors.items():\n",
    "            print(f\"{k}: {v}\")\n",
    "            quit()\n",
    "    else:\n",
    "        print(\"No errors found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_JSON(filename):\n",
    "    print(filename)\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = [json.loads(line) for line in f]\n",
    "\n",
    "    format_error_check(data, filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONL\\.jsonl\n",
      "No errors found\n",
      "JSONL\\100-civics-questions-and-answers-with-mp3-audio-spanish-version-0.jsonl\n",
      "No errors found\n",
      "JSONL\\about-us.jsonl\n",
      "No errors found\n",
      "JSONL\\addresschange.jsonl\n",
      "No errors found\n",
      "JSONL\\adoption-information-saint-kitts-and-nevis.jsonl\n",
      "No errors found\n",
      "JSONL\\adoption.jsonl\n",
      "No errors found\n",
      "JSONL\\affirmative-asylum.jsonl\n",
      "No errors found\n",
      "JSONL\\ar-11.jsonl\n",
      "No errors found\n",
      "JSONL\\archive.jsonl\n",
      "No errors found\n",
      "JSONL\\archive_topic_id=16948&r_date_m%255Bvalue%255D%255Bmonth%255D=&r_date_y%255Bvalue%255D%255Byear%255D=&combine=&items_per_page=10&=Go.jsonl\n",
      "No errors found\n",
      "JSONL\\archive_topic_id=16948&r_date_m%5Bvalue%5D%5Bmonth%5D=&r_date_y%5Bvalue%5D%5Byear%5D=&combine=&items_per_page=10.jsonl\n",
      "No errors found\n",
      "JSONL\\archive_topic_id=16955&r_date_m%5Bvalue%5D%5Bmonth%5D=&r_date_y%5Bvalue%5D%5Byear%5D=&combine=&items_per_page=10.jsonl\n",
      "No errors found\n",
      "JSONL\\avoid-scams.jsonl\n",
      "No errors found\n",
      "JSONL\\avoidscams.jsonl\n",
      "No errors found\n",
      "JSONL\\CAM.jsonl\n",
      "No errors found\n",
      "JSONL\\CHNV.jsonl\n",
      "No errors found\n",
      "JSONL\\citizenship.jsonl\n",
      "No errors found\n",
      "JSONL\\contactcenter.jsonl\n",
      "No errors found\n",
      "JSONL\\DACA.jsonl\n",
      "No errors found\n",
      "JSONL\\downloading-and-printing-immigration-forms.jsonl\n",
      "No errors found\n",
      "JSONL\\eadautoextend.jsonl\n",
      "No errors found\n",
      "JSONL\\employment-authorization.jsonl\n",
      "No errors found\n",
      "JSONL\\eoir-29.jsonl\n",
      "No errors found\n",
      "JSONL\\EOY2023.jsonl\n",
      "No errors found\n",
      "JSONL\\exploring-asylum-officer-careers.jsonl\n",
      "No errors found\n",
      "JSONL\\family.jsonl\n",
      "No errors found\n",
      "JSONL\\faq-family-reunification-parole-processes.jsonl\n",
      "No errors found\n",
      "JSONL\\fees.jsonl\n",
      "No errors found\n",
      "JSONL\\file-online.jsonl\n",
      "No errors found\n",
      "JSONL\\form-filing-tips.jsonl\n",
      "No errors found\n",
      "JSONL\\form-i-130-filing-information-for-prospective-adoptive-parents-living-abroad.jsonl\n",
      "No errors found\n",
      "JSONL\\forms-filing-tips.jsonl\n",
      "No errors found\n",
      "JSONL\\forms_topic_id=1128.jsonl\n",
      "No errors found\n",
      "JSONL\\forms_topic_id=1130&search_q=&sort_bef_combine=sticky+ASC.jsonl\n",
      "No errors found\n",
      "JSONL\\forms_topic_id=1132.jsonl\n",
      "No errors found\n",
      "JSONL\\FRP.jsonl\n",
      "No errors found\n",
      "JSONL\\frpinvitations.jsonl\n",
      "No errors found\n",
      "JSONL\\fwvp.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1041.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1041a.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=ar-11.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=eoir-29.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-1041.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-1041a.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-1145.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-1450.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-1566.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-28.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-28i.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-325a.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-845.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-845_sup.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=g-884.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-102.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-129cw.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-129cwr.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-129f.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-129s.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-130.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-131.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-131a.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-134.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-140.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-191.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=I-192.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-193.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-212.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-290b.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-356.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-360.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-361.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-363.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-407.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-485.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-485_supa.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-485_supj.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-508.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-526.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-526e.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-539.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-566.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-589.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-601.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-601a.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-602.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-612.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-687.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-690.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-693.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-694.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-698.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-730.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-751.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-765.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-765v.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-817.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-821.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-821d.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-824.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-829.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-854.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-864.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-864a.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-864ez.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-864w.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-865.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-9.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-90.jsonl\n",
      "No errors found\n",
      "JSONL\\g-1055_form=i-905.jsonl\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for dirpath, _, filenames in os.walk('JSONL'):\n",
    "    for filename in filenames:\n",
    "        full_path = os.path.join(dirpath, filename)\n",
    "\n",
    "        # read file on a snigle line and format each JSON object on one line\n",
    "        single_line_jsonl = load_single_line_string_from_file(full_path, delim='').replace('}{', '}\\n{')\n",
    "        \n",
    "        with open(full_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(single_line_jsonl)\n",
    "\n",
    "        # Load the dataset\n",
    "        dataset.append(load_JSON(full_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
